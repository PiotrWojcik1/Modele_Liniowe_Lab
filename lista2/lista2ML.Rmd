---
title: "Raport 2"
author: "Piotr Wojcik"
date: "11/2/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
<p>W poniższych zadaniach będziemy pracować na zbiorze danych zawierającym relację między ilością kserokopiarek i czasem(w godzinach) jaki potrzeba na ich konserwację.</p>
```{r including_data, echo = TRUE, warning = FALSE, tidy = TRUE}
data <- read.table("CH01PR20.txt", col.names = c("time","quantity"))
```
<h2>Zadanie 1</h2>
<p>Analizę powyższych danych zaczniemy od wyznaczenia ich na wykresie, gdzie pionowa oś będzie czasem(w godzinach) konserwacji, natomiast pozioma, ilością kserokopiarek.</p>
```{r plot_data1, echo = TRUE, warning = FALSE, tidy = TRUE}
plot(data$quantity, data$time, main = NULL, ylab = "czas(h)", xlab = "ilość(szt)", col = "blue", pch = 19)
```
<p>Patrząc na wykres można zauważyć, że dane w przybliżeniu układają się w pewną prostą, którą będziemy w kolejnym zadaniu wyznaczać.</p>

<h2>Zadanie 2</h2>
<p>W poniższym zadaniu będziemy szukać prostej, która będzie dobrze przybliżać analizowaną relację. Znaczy to, że chcemy wyznaczyć punkty $\small \beta_0, \beta_1$, takie że:</p>
$$
Y_i = \beta_1X_i + \beta_0 + \xi_i,
$$
<p>gdzie $\small (X_i,Y_i)$ to elementy naszej relacji, natomiast $\xi_i$ to zmienna losowa o rozkładzie normalnym $\small N(0,\sigma^2)$, gdzie dla każdego $\small i \neq j$ mamy $\small cov(\xi_i, \xi_j) = 0$.<p>
<p>W rzeczywistości nie będziemy szukać dokładnych wartości naszych parametrów, tylko przybliżać je poniższymi estymatorami:</p>
$$
\hat{\beta_1} = \frac{\sum_{i = 1}^n{(X_i-\overline{X})(Y_i-\overline{Y})}}{\sum_{i = 1}^n{(X_i-\overline{X})^2}} \\
\hat{\beta_0} = \overline{Y} - \hat{\beta_1} \overline{X} \\
\hat{\sigma}^2 = \frac{1}{n-2}\sum_{i=1}^n{(Y_i - \hat{\beta_0} - \beta_1X_i)^2}
$$
```{r estimators_ex2, echo = TRUE, warning = FALSE, tidy = TRUE}
B1_estimator <- function(x, y) {
  return(sum((x-mean(x))*(y-mean(y)))/sum((x-mean(x))^2))
}
B0_estimator <- function(x, y) {
  return(mean(y) - B1_estimator(x,y)*mean(x))
}
sigma2_estimator <- function(x,y) {
  return(1/(length(x)-2)*sum((y - B0_estimator(x,y) - B1_estimator(x,y)*x)^2))
}

beta1 <- B1_estimator(data$quantity, data$time)
beta0 <- B0_estimator(data$quantity, data$time)
sigma <- sqrt(sigma2_estimator(data$quantity, data$time))
```
<p>Podstawiając nasze dane do powyższych estymatorów otrzymujemy współczynniki do prostej postaci:</p>
$$
y = \beta_1 x + \beta_0 = `r round(beta1,3)`x `r round(beta0, 3)`.
$$
<p>Teraz wyznaczymy 95% przedział ufności dla parametu $\small \beta_1$ postaci:
$$
\left[ \hat{\beta_1} - t_c s(\hat{\beta_1}) , \hat{\beta_1} + t_c s(\hat{\beta_1})  \right],
$$
<p>gdzie $\small t_c$, to kwantyl rzędu $\small 1 - \frac{0.05}{2}$ dla rozkładu studenta z $\small n - 2$ stopniami swobody, gdzie $\small n$ to ilość obserwacji, natomiast $\small s^2(\hat{\beta_1})$ wynosi:</p>
$$
s^2(\hat{\beta_1}) = \frac{\hat{\sigma}^2}{\sum_{i = 1}^n{(X_i-\overline{X})^2}}.
$$
```{r conf_int_data, echo = TRUE, warning = FALSE, tidy = TRUE}
s2_beta1_function <- function(x, s) {
  return(s^2/(sum((x-mean(x))^2)))
}
s_beta1 <- sqrt(s2_beta1_function(data$quantity, sigma))
tc <- qt(1-0.05/2, df = length(data$quantity) - 2)
```
<p>Podstawiając wszystkie dane otrzymujemy przedział ufności postaci:</p>
$$
\left[ `r round(beta1-tc*s_beta1 ,3)` , `r round(beta1+tc*s_beta1 ,3)` \right].
$$
<p>Zajmiemy się teraz ustaleniem istotności parametru $\small \beta_1$, to znaczy, wykonamy test studenta dla parametru $\small \beta_1$ z hipotezą zerową $\small H_0: \beta_1 = 0$ i hipotezą alternatywną $\small H_A: \beta_1 \neq 0$.</p>
<p>Statystyka testowa wynosi:</p>
$$
T = \frac{\hat{\beta_1}}{s(\beta_1)} = `r round(beta1/s_beta1 ,3)`.
$$
<p>Teraz, jeżeli $\small |T| > t_c$, gdzie $\small t_c$ jest takie jak ostatnio, to odrzucimy hipotezę zerową, przez co wykażemy istotny związek między zminennymi $\small X$ i $\small Y$ w naszym modelu.</p>
<p>Istotnie, $\small |T| = `r abs(round(beta1/s_beta1 ,3))` > `r round(tc,3)` = t_c$, stąd odrzucamy hipotezę zerową $\small H_0: \beta_1 = 0$. Dla lepszego wglądu wyznaczymy <em>p-wartość</em> równą $\small p = P(|t| > |T|) = `r 2*pt(beta1/s_beta1,43, lower.tail = FALSE)`$. Ponieważ jest ona bardzo bliska zera, stąd wniosek, że mamy nawet większą pewność(niż na poziomie 95%), że hipoteza zerowa nie zachodzi. Takie wyniki można zinterpretować również w taki sposób, że uzależnienie czasu potrzebnego do konserwacji kserokopiarek od ich ilości, jest bardzo słuszne.</p>

<h2>Zadanie 3</h2>
<p>W poniższym zadaniu, wyznaczymy 95% przedział ufności dla średniego czasu konserwacji, jeżeli wiemy, że mamy do dyspozycji $\small 11$ kserokopiarek.</p>
<p>Zadanie zaczniemy od wyznaczenia średniego czasu konserwacji dla jedenastu kserokopiarek. Jest on postaci:</p>
$$
\hat{\mu_{11}} = \hat{\beta_0} + \hat{\beta_1}X_{11}.
$$
<p>Dostajemy stąd, że $\small \mu_{11} = `r round(beta0 + beta1*11 ,3)`$. Co zdaje się zgadzać z wykresem naszej relacji:</p>
```{r plot_with_pred_point, echo = TRUE, warning = FALSE, tidy = TRUE}
mu_11 <- beta0 + beta1*11
colors = c(sapply(1:45, function(x)"#611a99"),"red")
plot(c(data$quantity, 11), c(data$time, mu_11), main = NULL, ylab = "czas(h)", xlab = "ilość(szt)", col = colors, pch = 19, xlim = c(0,12))
lines(seq(0,20,by=10), beta0 + beta1*seq(0,20,by=10), col = "#1e991a", lwd = 2)
```
<p>Mając już $\small \hat{\mu_{11}}$, możemy wyznaczyć nasz przedział ufności, który jest postaci:</p>
$$
\left[ \hat{\mu_{11}} - t_c s(\hat{\mu_{11}}), \hat{\mu_{11}} + t_c s(\hat{\mu_{11}}) \right],
$$
<p>gdzie $\small t_c$ wynosi tyle co dotychczas, natomiast $\small s(\hat{\mu_{11}})$ wynosi:</p>
$$
s^2(\hat{\mu_{11}}) = \hat{\sigma}^2\left( \frac{1}{n} + \frac{(X_{11} - \overline{X})^2}{\sum_{i = 1}^n{(X_i-\overline{X})^2}} \right).
$$
```{r ex3data, echo = TRUE, warning = FALSE, tidy = TRUE}
s2_mu <- function(v, x, s) {
  return(s^2*(1/length(x) + (v-mean(x))^2/(sum((x-mean(x))^2))))
}
s_mu_11 <- sqrt(s2_mu(11, data$quantity, sigma))
```
<p>Po obliczeniu wszystkich potrzebnych danych, możemy wyznaczyć nasz 95% przedział ufności dla średniego czasu jaki oczekujemy przy jedenastu kserokopiarkach:</p>
$$
[`r round(mu_11 - tc*s_mu_11, 3)`, `r round(mu_11 + tc*s_mu_11, 3)`].
$$
<p>Jak widać, jest on całkiem szeroki, co sugeruje, że wartość którą wyestymowaliśmy może jeszcze znacznie odbiegać od rzeczywistej.</p>

<h2>Zadanie 4</h2>
<p>Zajmiemy się teraz 95% przedziałem predykcji dla nowej zmiennej $\small Y_{11}$, przy założeniu, że mamy do dyspozycji jedenaście kserokopiarek. Jest to przedział, w którym z prawdopodobieństwem $\small 0.95$ znajdować się będzie nasza nowa wartość $\small Y_{11}$.</p>
<p>Oczywiście estymator $\small Y_{11}$ jest równy rozważanemu w poprzednim zadaniu estymatorowi średniej $\small \mu_{11}$. Jedyna różnica jaka nastąpi to w $\small s(\hat{Y_{11}})$, mianowicie:</p>
$$
s^2(\hat{Y_{11}}) = \hat{\sigma}^2\left(1 + \frac{1}{n} + \frac{(X_{11} - \overline{X})^2}{\sum_{i = 1}^n{(X_i-\overline{X})^2}} \right).
$$
```{r ex4data, echo = TRUE, warning = FALSE, tidy = TRUE}
s2_Y <- function(v, x, s) {
  return(s^2*(1 + 1/length(x) + (v-mean(x))^2/(sum((x-mean(x))^2))))
}
s_Y_11 <- sqrt(s2_Y(11, data$quantity, sigma))
```
<p>Z tych wszystkich wartości uzyskujemy nasz przedział predykcyjny postaci:</p>
$$
\left[ \hat{Y_{11}} - t_c s(\hat{Y_{11}}), \hat{Y_{11}} + t_c s(\hat{Y_{11}}) \right] \\
[`r round(mu_11 - tc*s_Y_11, 3)`, `r round(mu_11 + tc*s_Y_11, 3)`].
$$
<p>Jak widać, przedział jaki uzyskaliśmy jest bardzo szeroki. Było oczywistym, że będzie on szerszy od tego w poprzednim zadaniu, gdyż wcześniej znaczny wpływ miały pozostałe dane, mianowicie, przewidywaliśmy ich średnią. W tym przypadku przewidujemy wartość poszczególnego wyrazu, co zwiększa nasze możliwości dobrania wyrazu $\small Y_{11}$.</p>
